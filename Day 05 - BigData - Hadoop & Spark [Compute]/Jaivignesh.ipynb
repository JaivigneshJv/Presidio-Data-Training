{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88925b7-9b64-4271-a290-d70bbda5c774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
      "|      Date|Name of State / UT|Latitude|Longitude|Total Confirmed cases|Death|Cured/Discharged/Migrated|New cases|New deaths|New recovered|\n",
      "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
      "|2020-01-30|            Kerala| 10.8505|  76.2711|                  1.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-01-31|            Kerala| 10.8505|  76.2711|                  1.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-01|            Kerala| 10.8505|  76.2711|                  2.0|    0|                      0.0|        1|         0|            0|\n",
      "|2020-02-02|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        1|         0|            0|\n",
      "|2020-02-03|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-04|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-05|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-06|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-07|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-08|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-09|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-10|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-11|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-12|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-13|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-14|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-15|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-16|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-17|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "|2020-02-18|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
      "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lower, max, month, sum\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"COVID Data Analysis\").getOrCreate()\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = spark.read.csv(\"complete.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Show the first few rows\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598d3d10-3859-4edb-b438-add783bf2b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Name of State / UT: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Total Confirmed cases: double (nullable = true)\n",
      " |-- Death: string (nullable = true)\n",
      " |-- Cured/Discharged/Migrated: double (nullable = true)\n",
      " |-- New cases: integer (nullable = true)\n",
      " |-- New deaths: integer (nullable = true)\n",
      " |-- New recovered: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ff2bbf-7953-40db-83f9-ee5521dfaf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|  Name of State / UT|\n",
      "+--------------------+\n",
      "|               delhi|\n",
      "|         maharashtra|\n",
      "|           meghalaya|\n",
      "|              odisha|\n",
      "|             haryana|\n",
      "|         west bengal|\n",
      "|                 goa|\n",
      "|              punjab|\n",
      "|   jammu and kashmir|\n",
      "|dadra and nagar h...|\n",
      "|           karnataka|\n",
      "|      andhra pradesh|\n",
      "|           telangana|\n",
      "|            nagaland|\n",
      "|               bihar|\n",
      "|      madhya pradesh|\n",
      "|           jharkhand|\n",
      "|               assam|\n",
      "|              kerala|\n",
      "|          tamil nadu|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the \"Name of State / UT\" column to lowercase for consistency\n",
    "df = df.withColumn(\"Name of State / UT\", lower(col(\"Name of State / UT\")))\n",
    "\n",
    "# Show the distinct state/UT names in the updated DataFrame\n",
    "distinct_states = df.select(\"Name of State / UT\").distinct()\n",
    "distinct_states.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d24c3c21-993b-42bd-ab0c-5b67040c3887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The day with the greatest number of COVID cases: 2020-07-18 with 70962 cases.\n"
     ]
    }
   ],
   "source": [
    "# 1. Day with the greatest number of COVID cases\n",
    "max_cases_day = df.groupBy(\"Date\") \\\n",
    "    .agg(sum(\"New cases\").alias(\"Total Confirmed\")) \\\n",
    "    .orderBy(col(\"Total Confirmed\").desc()) \\\n",
    "    .first()\n",
    "\n",
    "max_cases_date = max_cases_day[\"Date\"]\n",
    "max_cases_count = max_cases_day[\"Total Confirmed\"]\n",
    "\n",
    "print(f\"The day with the greatest number of COVID cases: {max_cases_date} with {max_cases_count} cases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b038261-7b8e-43e5-9afb-f8b7f72b87e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The state with the second-largest number of COVID cases: tamil nadu with 273459 cases.\n"
     ]
    }
   ],
   "source": [
    "# 2. State with the second-largest number of COVID cases\n",
    "state_cases = df.groupBy(\"Name of State / UT\") \\\n",
    "    .agg(sum(\"New cases\").alias(\"Total Confirmed\")) \\\n",
    "    .orderBy(col(\"Total Confirmed\").desc())\n",
    "\n",
    "second_largest_state = state_cases.collect()[1]  # Index 1 gives the second-largest\n",
    "\n",
    "print(f\"The state with the second-largest number of COVID cases: {second_largest_state['Name of State / UT']} with {second_largest_state['Total Confirmed']} cases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04acf4c4-f0c0-4c38-b13a-5d9ea210a360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Union Territory with the least number of deaths: union territory of ladakh with 0.0 deaths.\n"
     ]
    }
   ],
   "source": [
    "# 3. Union Territory with the least number of deaths\n",
    "unique_states = [row[0] for row in distinct_states.collect()]\n",
    "\n",
    "union_territory_deaths = df.filter(col(\"Name of State / UT\").isin(unique_states)) \\\n",
    "    .groupBy(\"Name of State / UT\") \\\n",
    "    .agg(sum(\"Death\").alias(\"Total Deaths\")) \\\n",
    "    .orderBy(col(\"Total Deaths\").asc()) \\\n",
    "    .first()\n",
    "\n",
    "print(f\"The Union Territory with the least number of deaths: {union_territory_deaths['Name of State / UT']} with {union_territory_deaths['Total Deaths']} deaths.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81adcb3c-033a-46ba-881a-625046556f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The state with the lowest Death to Total Confirmed cases ratio: union territory of ladakh with a ratio of 0.0.\n"
     ]
    }
   ],
   "source": [
    "# 4. State with the lowest Death to Total Confirmed cases ratio\n",
    "df_with_ratio = df.withColumn(\"Death_to_Confirmed_Ratio\", col(\"Death\") / col(\"Total Confirmed cases\"))\n",
    "\n",
    "lowest_ratio_state = df_with_ratio.groupBy(\"Name of State / UT\") \\\n",
    "    .agg(max(\"Death_to_Confirmed_Ratio\").alias(\"Max Ratio\")) \\\n",
    "    .orderBy(col(\"Max Ratio\").asc()) \\\n",
    "    .first()\n",
    "\n",
    "print(f\"The state with the lowest Death to Total Confirmed cases ratio: {lowest_ratio_state['Name of State / UT']} with a ratio of {lowest_ratio_state['Max Ratio']}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04d68258-4980-4009-bd49-9ed8df05943e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The month with the most new recovered cases: July with 722983 recoveries.\n"
     ]
    }
   ],
   "source": [
    "# 5. Month with the most new recovered cases\n",
    "df_with_month = df.withColumn(\"Month\", month(col(\"Date\")))\n",
    "\n",
    "max_recovered_month = df_with_month.groupBy(\"Month\") \\\n",
    "    .agg(sum(\"New recovered\").alias(\"Total Recovered\")) \\\n",
    "    .orderBy(col(\"Total Recovered\").desc()) \\\n",
    "    .first()\n",
    "\n",
    "month_mapping = {\n",
    "    1: \"January\", 2: \"February\", 3: \"March\", 4: \"April\", 5: \"May\",\n",
    "    6: \"June\", 7: \"July\", 8: \"August\", 9: \"September\", 10: \"October\",\n",
    "    11: \"November\", 12: \"December\"\n",
    "}\n",
    "\n",
    "max_recovered_month_name = month_mapping[max_recovered_month[\"Month\"]]\n",
    "print(f\"The month with the most new recovered cases: {max_recovered_month_name} with {max_recovered_month['Total Recovered']} recoveries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79dd670-bcbd-4ee3-8ab9-5adf859cb16e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspark_env)",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
